---
import SocialList from "@/components/SocialList.astro";
// import PostPreview from "@/components/blog/PostPreview.astro";
// import { Icon } from "astro-icon/components";
// import { Image } from 'astro:assets';
import PageLayout from "@/layouts/Base.astro";
import pub1Image from "../assets/pub1.png";
import pub3Image from "../assets/pub3.gif";
import { Icon } from "astro-icon/components";

// import { getAllPosts, sortMDByDate } from "@/data/post";
// const MAX_POSTS = 10;
// const allPosts = await getAllPosts();
// const allPostsByDate = sortMDByDate(allPosts).slice(0, MAX_POSTS);

const cactusTech = [
	{
		author: ["Xu Pan", "Zimin Xia", "Xianwei Zheng"],
		title: "Scale-aware Co-visible Region Detection for Image Matching",
		booktitle: "ISPRS Journal of Photogrammetry and Remote Sensing",
		time: "2025",
		doi: "https://doi.org/10.1016/j.isprsjprs.2025.08.015",
		paper: "https://www.sciencedirect.com/science/article/abs/pii/S0924271625003260",
		code: "https://github.com/Geo-Tell/SCoDe",
		image: pub1Image.src,
		venueIcon: "simple-icons:elsevier",
		venueColor: "#FF6C00",
		abstract: "Matching images with significant scale differences remains a persistent challenge in photogrammetry and remote sensing. The scale discrepancy often degrades appearance consistency and introduces uncertainty in keypoint localization. While existing methods address scale variation through scale pyramids or scale-aware training, matching under significant scale differences remains an open challenge. To overcome this, we address the scale difference issue by detecting co-visible regions between image pairs and propose SCoDe (Scale-aware Co-visible region Detector), which both identifies co-visible regions and aligns their scales for highly robust, hierarchical point correspondence matching. Specifically, SCoDe employs a novel Scale Head Attention mechanism to map and correlate features across multiple scale subspaces, and uses a learnable query to aggregate scale-aware information of both images for co-visible region detection. In this way, correspondences can be established in a coarse-to-fine hierarchy, thereby mitigating semantic and localization uncertainties. Extensive experiments on three challenging datasets demonstrate that SCoDe outperforms state-of-the-art methods, improving the precision of a modern local feature matcher by 8.41%. Notably, SCoDe shows a clear advantage when handling images with drastic scale variations.",
	},
	{
		author: ["Xu Pan", "Qiyuan Ma", "Jintao Zhang", "Xianwei Zheng"],
		title: "SAMatcher: Segment Anything Co-visible for Robust Feature Matching",
		booktitle: "(In Preparation)",
		time: "2026",
		doi: "",
		paper: "",
		code: "",
		image: "",
		venueIcon: "simple-icons:latex",
		venueColor: "#008080",
		abstract: "",
	},
	{
		author: ["Xu Pan", "Zhenglin Wan", "Xingrui Yu"],
		title: "Flow-Matching RL with Streaming Spatial Perception for Dynamic Manipulation",
		booktitle: "(In Preparation)",
		time: "2026",
		doi: "",
		paper: "",
		code: "",
		image: pub3Image.src,
		venueIcon: "simple-icons:latex",
		venueColor: "#008080",
		abstract: "",
	},
];
/* Dynamically gather experience logos */
const experienceMeta: Record<string, { name: string; link: string }> = {
	"exp1.png": {
		name: "Wuhan University",
		link: "https://en.whu.edu.cn/",
	},
	"exp2.png": {
		name: "State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing (LIESMARS)",
		link: "https://liesmars.whu.edu.cn/",
	},
	"exp3.png": {
		name: "Baidu, Inc. (International Technology R&D Department)",
		link: "https://www.baidu.com/",
	},
	"exp4.png": {
		name: "Centre for Frontier AI Research (CFAR), Agency for Science, Technology and Research (A*STAR)",
		link: "https://www.a-star.edu.sg/cfar",
	},
};

const expImages = import.meta.glob("../assets/exps/*.{png,jpg,jpeg,svg,webp}", {
	eager: true,
	import: "default",
});

// Preserve intended display order (fallback to filename order if new files are added)
const order = ["exp1.png", "exp2.png", "exp3.png", "exp4.png"];

const experiences = Object.entries(expImages)
	.map(([path, mod]: [string, any]) => {
		const file = path.split("/").pop() || "";
		const meta = experienceMeta[file] || { name: file, link: "#" };
		return {
			file,
			src: (mod as any).src,
			name: meta.name,
			link: meta.link,
		};
	})
	.sort((a, b) => {
		const ai = order.indexOf(a.file);
		const bi = order.indexOf(b.file);
		if (ai === -1 && bi === -1) return a.file.localeCompare(b.file);
		if (ai === -1) return 1;
		if (bi === -1) return -1;
		return ai - bi;
	});
---

<PageLayout meta={{ title: "Home" }}>
	<section>
		<h1 class="title mb-6">Hello World!</h1>
		<p class="mb-4">
			Hi, I’m currently a Master's student in the
			<a class="cactus-link" href="https://liesmars.whu.edu.cn/"
				>State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing
				(LIESMARS)</a
			>
			at <a class="cactus-link" href="https://en.whu.edu.cn/">Wuhan University</a>, under the
			guidance of
			<a class="cactus-link" href="https://jszy.whu.edu.cn/zhengxianwei/zh_CN/index.htm"
				>Prof. Xianwei Zheng</a
			>. I received my B.Eng. in Remote Sensing Science and Technology from Wuhan University in
			2023. I have previously researched GenAI applications in image and video generation under the
			supervision of
			<a class="cactus-link" href="https://scholar.google.com/citations?user=dcakOP4AAAAJ"
				>Dr. Yan Zhang</a
			>
			during my internship at
			<a class="cactus-link" href="https://www.baidu.com/"
				>Baidu, Inc. (International Technology R&D Department)</a
			>
			Currently, I am also a remote research intern at
			<a class="cactus-link" href="https://www.a-star.edu.sg/cfar"
				>Centre for Frontier AI Research (CFAR), Agency for Science, Technology and Research
				(A*STAR)</a
			>, supervised by
			<a class="cactus-link" href="https://xingruiyu.github.io/">Dr. Xingrui Yu</a>, where I work on
			reinforcement learning and embodied intelligence, with a focus on generalizable, agent-centric
			policy learning.
		</p>
		<p class="mb-4">
			My research interests lie in <em class="highlight">computer vision</em> and <em
				class="highlight">generative AI</em
			>, with a focus on unifying 2D and 3D representations through image correspondence, cross-view
			understanding, and structure-aware generation. I aim to develop general spatial intelligence
			models that bridge perception, geometry, and trustworthy generation at scale, advancing <em
				class="highlight">the next generation of spatially grounded, intelligent visual systems</em
			>. Beyond foundational research, I am particularly interested in enabling <em
				class="highlight">embodied intelligence</em
			> and <em class="highlight">autonomous agents</em>, where spatial reasoning and generative
			modeling empower real-world interaction, decision-making, and large-scale multi-agent
			collaboration.
		</p>
		<SocialList />
	</section>
	<section class="mt-12" aria-label="Experiences">
		<h2 class="title mb-4 text-xl">Experiences</h2>
		<div class="flex flex-wrap items-center gap-6">
			{
				experiences.map((exp) => (
					<a
						href={exp.link}
						target="_blank"
						rel="noopener"
						class="group relative flex items-center justify-center p-1"
					>
						<img
							src={exp.src}
							alt={exp.name}
							title={exp.name}
							class="h-14 w-auto object-contain transition-transform duration-200 group-hover:scale-105"
							loading="lazy"
						/>
						<span class="pointer-events-none absolute -bottom-7 left-1/2 -translate-x-1/2 whitespace-nowrap rounded bg-gray-800 px-2 py-0.5 text-[10px] font-medium tracking-wide text-white opacity-0 shadow transition-opacity group-hover:opacity-100">
							{exp.name}
						</span>
					</a>
				))
			}
		</div>
	</section>
	<section class="mt-16">
		<h2 class="title mb-4 text-xl">Publications</h2>
		<dl class="space-y-4">
			{
				cactusTech.map((pub) => {
					const { author, title, booktitle, time, doi, paper, code, abstract, venueIcon, venueColor, image } = pub;
					const slug = title
						.toLowerCase()
						.replace(/\s+/g, "-")
						.replace(/[^a-z0-9\-]/g, "");
					return (
						<article class="pub-article group relative w-full overflow-hidden rounded-xl border border-zinc-200/70 bg-white/80 p-4 shadow-sm backdrop-blur supports-[backdrop-filter]:bg-white/70 transition hover:shadow-md dark:border-zinc-800/80 dark:bg-zinc-900/80 -ml-2">
							{/* Use flow layout on large screens: text column grows, thumbnail has fixed size.
							   Small screens keep a single-column grid and the thumbnail remains hidden. */}
							<div class="grid grid-cols-1 gap-4 lg:flex lg:items-start lg:gap-6">
								{/* text column: allow shrinking/truncation */}
								<div class="min-w-0 lg:flex-1">
 									<h3 class="text-base font-semibold leading-snug tracking-tight">
 										<span class="text-accent"><strong>{title}</strong></span>
 									</h3>
 									<p class="mt-1 text-sm text-gray-700 dark:text-gray-300">
 										{author.map((name, index) => (
 											<span style={{ fontWeight: name === "Xu Pan" ? "bold" : "normal" }}>
 												{name}{index < author.length - 1 ? ", " : ""}
 											</span>
 										))}
 									</p>
 									<div class="mt-2 flex flex-wrap gap-2">
 										<span class="inline-flex items-center rounded-full bg-gray-100 px-2 py-0.5 text-[11px] font-medium text-gray-700 dark:bg-zinc-800 dark:text-gray-300">
 											{ /* render venue icon if available */ }
 											{venueIcon && (
 												<Icon name={venueIcon} width="14" height="14" class="mr-1 inline-block align-[-0.2em]" style={`color: ${venueColor}`} aria-hidden="true" />
 											)}
 											{booktitle}
 										</span>
 										{time && (
 											<span class="rounded-full bg-gray-100 px-2 py-0.5 text-[11px] font-medium text-gray-700 dark:bg-zinc-800 dark:text-gray-300">{time}</span>
 										)}
 									</div>
 									<div class="mt-3 flex flex-wrap gap-2" aria-label="Publication actions">
 										{abstract && (
 											<button
 												type="button"
 												class="abstract-btn cactus-link inline-flex items-center rounded border border-zinc-300 px-2.5 py-1 text-xs font-medium text-gray-700 dark:text-gray-300 transition hover:bg-accent/10 dark:border-zinc-700"
 												data-abstract-id={`abstract-${slug}`}
 												aria-expanded="false"
 											>
 												ABSTRACT
 												<svg class="chev transform ml-2 h-3 w-3 transition-transform duration-200" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg" aria-hidden="true">
 													<path d="M6 8l4 4 4-4" stroke="currentColor" stroke-width="1.6" stroke-linecap="round" stroke-linejoin="round" />
 												</svg>
 											</button>
 										)}
 										{code && (<a class="cactus-link inline-flex items-center rounded border border-zinc-300 px-2.5 py-1 text-xs font-medium text-gray-700 dark:text-gray-300 transition hover:bg-accent/10 dark:border-zinc-700" href={code} target="_blank" rel="noopener">CODE</a>)}
 										{doi && (<a class="cactus-link inline-flex items-center rounded border border-zinc-300 px-2.5 py-1 text-xs font-medium text-gray-700 dark:text-gray-300 transition hover:bg-accent/10 dark:border-zinc-700" href={doi} target="_blank" rel="noopener">DOI</a>)}
 										{paper && (<a class="cactus-link inline-flex items-center rounded border border-zinc-300 px-2.5 py-1 text-xs font-medium text-gray-700 dark:text-gray-300 transition hover:bg-accent/10 dark:border-zinc-700" href={paper} target="_blank" rel="noopener">PAPER</a>)}
 									</div>
 								</div>
 								{/* thumbnail column (part of flow on large screens). Keep hidden on small screens. */}
 								{image && (
 									<div class="pub-thumb hidden lg:block lg:ml-2">
 										<button type="button" class="pub-thumb-btn group block cursor-zoom-in" aria-label="Open image">
 											<img src={image} alt="[Thumbnail]" class="pub-thumb-img h-[96px] w-[96px] rounded-xl object-cover shadow-md transition duration-200 group-hover:scale-[1.04] group-hover:shadow-lg border-2 border-transparent group-hover:border-accent group-hover:border-dashed" loading="lazy" decoding="async" />
 										</button>
 									</div>
 								)}
 							</div>
							{/* 抽出的摘要区域：宽度为整个卡片（在小/大屏均为 full width） */}
							{abstract && (
								<div class="abstract-collapse mt-3 overflow-hidden transition-[max-height,opacity] duration-300 ease-in-out text-sm text-gray-700 dark:text-gray-300 w-full" id={`abstract-content-${slug}`} style="max-height: 0; opacity: 0;" data-collapsed="true">
									{abstract}
								</div>
							)}
 						</article>
 					);
 				})
 			}
 		</dl>
 	</section>

	{/* Image modal (reused) */}
	<div id="img-modal" class="fixed inset-0 z-70 hidden flex items-center justify-center bg-black/40 backdrop-blur-sm p-4">
		<div class="relative max-w-[90vw] max-h-[90vh] flex items-center justify-center">
			<button id="img-modal-close" class="absolute right-3 top-3 z-20 inline-flex h-9 w-9 items-center justify-center rounded-full bg-white/90 hover:bg-white text-accent shadow-md" aria-label="Close image modal">
				<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="16" height="16" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true">
					<line x1="18" y1="6" x2="6" y2="18"></line>
					<line x1="6" y1="6" x2="18" y2="18"></line>
				</svg>
			</button>
			<img id="img-modal-img" src="" alt="Large image" class="max-w-full max-h-[90vh] rounded-lg shadow-xl object-contain" />
		</div>
	</div>

	<script>
		document.addEventListener("DOMContentLoaded", () => {
			// toggle abstracts: smooth max-height + opacity, no image panel logic
			document.querySelectorAll('.abstract-btn').forEach(btn => {
				const id = btn.getAttribute('data-abstract-id');
				const slug = id ? id.replace('abstract-', '') : null;
				const content = slug ? document.getElementById(`abstract-content-${slug}`) : null;
				const chev = btn.querySelector('.chev');
				if (chev && content) {
					const collapsed = content.getAttribute('data-collapsed');
					if (collapsed === 'false') chev.classList.add('rotate-180'); else chev.classList.remove('rotate-180');
				}
				btn.addEventListener('click', () => {
					if (!content) return;
					const collapsed = content.getAttribute('data-collapsed') !== 'false';
					if (collapsed) {
						content.style.maxHeight = content.scrollHeight + 'px';
						content.style.opacity = '1';
						content.setAttribute('data-collapsed', 'false');
						btn.setAttribute('aria-expanded', 'true');
						if (chev) chev.classList.add('rotate-180');
						setTimeout(() => { if (content.getAttribute('data-collapsed') === 'false') content.style.maxHeight = 'none'; }, 310);
					} else {
						content.style.maxHeight = content.scrollHeight + 'px';
						content.getBoundingClientRect();
						content.style.maxHeight = '0';
						content.style.opacity = '0';
						content.setAttribute('data-collapsed', 'true');
						btn.setAttribute('aria-expanded', 'false');
						if (chev) chev.classList.remove('rotate-180');
					}
				});
			});

			// Image modal handlers: thumbnails open modal
			const imgModal = document.getElementById('img-modal') as HTMLDivElement | null;
			const imgModalImg = document.getElementById('img-modal-img') as HTMLImageElement | null;
			const imgModalClose = document.getElementById('img-modal-close') as HTMLButtonElement | null;
			function openImgModal(src: string): void {
				if (!imgModal || !imgModalImg) return;
				imgModalImg.src = src;
				imgModal.classList.remove('hidden');
				document.body.style.overflow = 'hidden';
				imgModalClose?.focus();
			}
			function closeImgModal(): void {
				if (!imgModal) return;
				imgModal.classList.add('hidden');
				if (imgModalImg) imgModalImg.src = '';
				document.body.style.overflow = '';
			}
			imgModalClose?.addEventListener('click', closeImgModal);
			imgModal?.addEventListener('click', (e) => { if (e.target === imgModal) closeImgModal(); });
			document.addEventListener('keydown', (e) => { if (e.key === 'Escape') closeImgModal(); });

			// thumbnail click -> open modal
			document.addEventListener('click', (e) => {
				const target = e.target as EventTarget | null;
				if (!target) return;
				if (target instanceof HTMLImageElement) {
					// thumbnail image
					if (target.classList.contains('pub-thumb-img')) {
						openImgModal(target.src);
						return;
					}
					// inline images (if any) still open modal
					if (target.dataset && target.dataset.inline === 'true') {
						openImgModal(target.src);
					}
				}
			});
		});
	</script>
</PageLayout>
